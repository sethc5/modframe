# Artificial Intelligence Governance Levers

**Summary:** Federal AI governance as of early 2026 operates primarily through reversible executive action — executive orders, OMB memoranda, and NIST voluntary frameworks — rather than through statutory authority, creating a governance architecture where AI regulation can be substantially reversed, modified, or abandoned by a new administration without congressional action. [Observed] Executive Order 14110 (October 2023) established the foundational Biden-era AI governance framework, requiring safety testing for frontier AI models, agency AI use policies, and creation of the NIST AI Safety Institute; the Trump administration rescinded EO 14110 and reversed most of its requirements within the first weeks of January 2025, including withdrawal from the international AI Safety Institute network. [Observed] The contrast with earlier technology governance regimes is stark: the FTC's authority over data practices (FTC Act Section 5), the FCC's telecommunications authorities (Communications Act), and the FDA's device approval requirements (FDCA) are all statutory and cannot be repealed by executive order alone. [Observed] The structural result is that AI — the most consequential emerging technology affecting federal administration and democratic processes — is governed by the least durable regulatory instrument, creating a ratchet risk where governance capacity built under one administration is reset to zero under the next. [Inferred]

**Mechanism in one sentence:** Federal AI governance rests primarily on executive orders and voluntary frameworks rather than statute, creating a governance architecture where AI regulation is reversible by administrative action alone and cannot accumulate institutional durability across administrations. [Observed]

### Actors and roles

- **National Institute of Standards and Technology (NIST)** — issued the AI Risk Management Framework (AI RMF 1.0, 2023) and established the AI Safety Institute (AISI); the AISI was defunded and withdrawn from international networks in early 2025. [Observed]
- **Office of Science and Technology Policy (OSTP)** — coordinated EO 14110 implementation across agencies; advisory, no independent regulatory authority. [Observed]
- **Office of Management and Budget (OMB)** — issued Memorandum M-24-10 requiring agency AI governance plans and risk management; the memorandum's mandatory requirements were subject to rescission under the new administration. [Observed]
- **Federal Trade Commission (FTC)** — has used its Section 5 unfairness authority to challenge AI applications that deceive consumers or cause consumer harm; this authority is statutory and persisted across the administration change. [Observed]
- **Sector regulators (FDA, FAA, SEC, CFPB)** — apply existing statutory authorities to AI applications in their sectors; FDA's software-as-medical-device framework and FAA's autonomous systems authorities are statutory and more durable than executive coordination. [Observed]
- **Congress** — has not enacted comprehensive federal AI governance legislation; multiple bills have been introduced but few enacted into law. [Observed]
- **European Union** — enacted the EU AI Act (effective 2024–2026 phase-in), the world's first comprehensive AI governance statute; its extraterritorial application to EU-serving AI systems creates de facto compliance requirements for U.S. firms. [Observed]

### Process map (bulleted)

- The executive branch identifies AI risk management priorities and issues an executive order directing agency action on safety testing, procurement standards, and use policies. [Observed]
- Agencies implement EO requirements through agency guidance, procurement regulations, and operational procedures; NIST develops voluntary frameworks that agencies and private sector adopt. [Observed]
- Congress holds hearings on AI but does not enact comprehensive legislation; sector-specific legislation advances more readily than horizontal frameworks. [Observed]
- A new administration takes office; executive AI governance architecture is reversed or substantially modified by executive order without congressional action. [Observed]
- NIST capacity built for AI safety evaluation is dismantled; the institutional investment made under the prior administration does not transfer. [Observed]
- Sector regulators continue applying existing statutory authority to AI applications within their jurisdiction; the FTC pursues consumer protection cases; FDA continues software-as-medical-device review. [Observed]

### Where power concentrates

- **Gatekeepers:** The President has near-unilateral authority over executive AI governance frameworks; the executive order mechanism concentrates AI policy development in the White House without requiring congressional consensus. [Observed]
- **Bottlenecks:** Congress's inability to pass comprehensive AI legislation reflects definitional complexity, jurisdictional competition among agencies, and the difficulty of reconciling innovation promotion with safety requirements. [Inferred]
- **Veto points:** The Senate filibuster requires 60-vote supermajority for most legislation; comprehensive AI governance legislation has not reached that threshold; only narrow bipartisan AI applications have been enacted. [Observed]

### Common failure modes

- The "pacing problem": AI capabilities advance faster than legislative and regulatory frameworks can be developed and enacted, creating a persistent gap between deployed capabilities and governance capacity. [Observed]
- Executive governance frameworks cannot bind the private sector without APA rulemaking; EO 14110's safety testing requirements applied to agencies and frontier model developers receiving federal contracts but did not bind the broader AI industry. [Observed]
- Voluntary frameworks (NIST AI RMF) are adopted unevenly; deployment outpaces adoption; the voluntary framework cannot address systemic risks from non-adopters. [Observed]
- The EU AI Act has become the effective global standard for U.S.-serving AI systems, meaning U.S. AI governance is being shaped by EU regulation rather than domestic statutory authority. [Observed]

### What evidence would prove/disprove key claims

- Executive order issuance and rescission records document the governance architecture changes across administrations. [Observed]
- NIST AI Safety Institute budget and staffing records (prior to 2025) and post-rescission status document the reversibility demonstrated in practice. [Observed]
- Compare the rate of comprehensive AI legislation enactment in EU (EU AI Act, 2024) vs. U.S. (no equivalent statute) as evidence of the statutory governance gap. [Observed]
- FTC AI enforcement case record shows which statutory AI harms can be addressed without new legislation. [Observed]

### Suggested sources

- Executive Order 14110, *Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence.* October 30, 2023. 88 Fed. Reg. 75191.
- Office of Management and Budget. *Memorandum M-24-10: Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence.* March 2024.
- National Institute of Standards and Technology. *Artificial Intelligence Risk Management Framework (AI RMF 1.0).* January 2023. URL: https://www.nist.gov/artificial-intelligence
- European Union. *AI Act,* Regulation (EU) 2024/1689 (effective August 2024).
- Administrative Procedure Act, 5 U.S.C. §§ 551–559.
- Government Accountability Office. *Artificial Intelligence: Agencies Have Begun Implementation but Need to Complete Key Requirements.* GAO-24-106811. URL: https://www.gao.gov

### Episode outline (6 parts)

1. **Structure:** Map the U.S. AI governance landscape as of early 2026 — what has been rescinded (EO 14110), what persists (sector statutory authorities, FTC Section 5), and what the EU AI Act imposes on U.S. firms — distinguishing statutory from executive governance instruments. [Observed]
2. **Incentive:** Explain why comprehensive AI legislation has not passed — definitional complexity, jurisdictional competition, Senate filibuster dynamics, and lobbying asymmetry between AI incumbent platforms and AI safety advocates. [Observed]
3. **Example:** Trace EO 14110's AI safety testing requirements through NIST implementation to the January 2025 reversal — documenting what was built, what was reversed, and the pace of institutional capacity destruction. [Observed]
4. **Evidence:** Present executive order issuance and rescission records; document NIST AI Safety Institute status changes; compare EU vs. U.S. AI governance legislative output. [Observed]
5. **Levers:** Evaluate statutory NIST AI Safety Institute authority, mandatory AI incident reporting requirements, sector-specific AI safety statutes, and a U.S. equivalent to the EU AI Act's horizontal risk-classification framework. [Hypothesis]
6. **Takeaway:** Federal AI governance is structured around the least durable regulatory instrument available — executive orders — creating a governance architecture that cannot accumulate institutional capacity across administrations at the pace that AI capability advances. [Inferred]
