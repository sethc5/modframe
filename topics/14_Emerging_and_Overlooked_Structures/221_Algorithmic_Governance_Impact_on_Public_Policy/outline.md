# Algorithmic Governance Impact on Public Policy

**Summary:** Federal agencies increasingly use algorithmic systems — automated scoring, predictive modeling, and machine-learning tools — to make or assist in high-stakes decisions affecting benefits eligibility, enforcement targeting, contract awards, and regulatory prioritization. [Observed] These systems operate without the notice-and-comment transparency required of formal rulemaking under the Administrative Procedure Act, the due process protections that govern individual agency adjudications, or the audit mechanisms that allow independent verification of accuracy and bias. [Observed] The Government Accountability Office has documented that federal use of AI and algorithmic tools has grown across more than two dozen agencies, but oversight frameworks have lagged behind deployment, leaving significant gaps in accountability for algorithmic errors or discriminatory outcomes. [Observed] The result is a governance layer — operating algorithmically below the level of formal rule — that concentrates decision-making power in technical systems whose logic is opaque to the people affected, the congressional overseers who fund the agencies, and often the agency managers who supervise the programs. [Inferred]

**Mechanism in one sentence:** Federal agencies deploy algorithmic decision systems that wield regulatory and benefits-determination power without the procedural transparency, due process protections, or audit mechanisms that govern equivalent human agency action. [Observed]

### Actors and roles

- **Federal agencies (HHS, SSA, DHS, DOJ, VA)** — procure, deploy, and operate algorithmic systems for a range of administrative functions; agency technical staff have significant discretion over system design and thresholds. [Observed]
- **Algorithm vendors and contractors** — private firms that develop and sell algorithmic tools to agencies; their systems are often proprietary, limiting independent review of methodology. [Observed]
- **Office of Science and Technology Policy (OSTP)** — issued the AI Bill of Rights (2022) as a non-binding framework for responsible AI deployment in federal programs; no enforcement authority. [Observed]
- **Office of Management and Budget (OMB)** — issued Memorandum M-24-10 (2024) requiring agency AI governance plans and risk management documentation; binding on agencies. [Observed]
- **Government Accountability Office (GAO)** — has audited federal AI deployment across agencies; identified oversight gaps and accountability shortfalls. [Observed]
- **Congressional oversight committees** — have held hearings on federal AI use but have not yet enacted comprehensive statutory framework governing algorithmic government. [Observed]
- **Civil society and legal advocates** — challenge specific algorithmic systems in litigation as violations of due process, APA notice requirements, or anti-discrimination statutes. [Observed]

### Process map (bulleted)

- An agency identifies a program area where automated scoring or predictive modeling could improve efficiency or fraud detection (e.g., SSA disability determination, DHS immigration risk scoring, VA benefits processing). [Observed]
- The agency procures an algorithmic tool through the federal contracting process; the vendor's methodology may be protected as proprietary trade secret, limiting transparency. [Observed]
- The agency deploys the tool to assist or replace human decision-making in individual case determinations; in many cases the algorithmic output is treated as authoritative unless the caseworker manually overrides. [Observed]
- Individuals affected by adverse algorithmic decisions often receive no explanation of the system's logic; appeals processes may be disconnected from the algorithmic workflow. [Observed]
- Congressional oversight relies on agency self-reporting; GAO reviews are episodic rather than continuous; no systematic audit mechanism exists for ongoing algorithmic performance. [Observed]
- When algorithmic bias or error produces discriminatory outcomes at scale, the affected population is often unable to identify the systemic cause of denials, limiting class-action challenge. [Inferred]

### Where power concentrates

- **Gatekeepers:** Agency technical staff and procurement officers who design algorithm specifications and select vendors determine the values, thresholds, and objectives embedded in systems that affect millions of people. [Observed]
- **Bottlenecks:** Proprietary vendor contracts limit external audit of algorithmic logic; agencies that depend on vendor systems may lack the internal technical capacity to evaluate whether systems perform as described. [Observed]
- **Veto points:** OMB OIRA reviews proposed formal rules under APA rulemaking, but algorithmic systems deployed below the level of formal rule are not routinely reviewed by OIRA, creating a regulatory gap. [Inferred]

### Common failure modes

- Algorithmic systems trained on historical data encode historical disparities, producing discriminatory outcomes that are statistically predictable but practically opaque to the individuals affected. [Observed]
- The APA's procedural protections apply differently to algorithmic systems depending on whether they constitute "final agency action" or are characterized as internal management tools — a distinction agencies can manipulate to limit review. [Observed]
- OMB's M-24-10 and OSTP's AI Bill of Rights are non-binding or have unclear enforcement teeth; the absence of statutory requirements means compliance is voluntary or lightly monitored. [Observed]
- Congress has not enacted a general federal AI governance statute as of early 2026; sectoral legislation (for health care, financial services, immigration) covers some applications but leaves significant gaps. [Observed]

### What evidence would prove/disprove key claims

- GAO reports on federal AI use provide systematic (if incomplete) documentation of which agencies deploy algorithmic tools and in which decision domains. [Observed]
- Litigation records from APA and due process challenges to specific algorithmic systems provide case-by-case evidence of harm. [Observed]
- Audit of vendor contracts via FOIA to assess how many include independent audit and bias-testing requirements. [Hypothesis]
- Comparison of algorithmic decision accuracy and disparate impact rates across demographic groups in programs where outcome data is available (e.g., SSA disability determinations). [Hypothesis — requires agency data access]

### Suggested sources

- Government Accountability Office. *Artificial Intelligence: Status of Developing and Acquiring Capabilities Across the Federal Government* (GAO-21-transition and subsequent). URL: https://www.gao.gov
- Office of Management and Budget. *Memorandum M-24-10: Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence.* March 2024. URL: https://www.whitehouse.gov/omb
- Office of Science and Technology Policy. *Blueprint for an AI Bill of Rights.* October 2022. URL: https://www.whitehouse.gov/ostp
- Administrative Procedure Act, 5 U.S.C. §§ 551–559 (rulemaking and adjudication requirements).
- Executive Order 14110, *Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence.* October 30, 2023. 88 Fed. Reg. 75191.
- National Institute of Standards and Technology. *AI Risk Management Framework (AI RMF 1.0).* January 2023. URL: https://www.nist.gov/artificial-intelligence

### Episode outline (6 parts)

1. **Structure:** Map how federal agencies acquire and deploy algorithmic systems — procurement process, vendor relationships, deployment in benefits and enforcement programs, and the gap between algorithmic workflow and APA procedural requirements. [Observed]
2. **Incentive:** Explain why agencies adopt algorithmic tools (efficiency, cost reduction, consistency) and why oversight frameworks have lagged — technical complexity, limited GAO audit capacity, congressional unfamiliarity, and vendor trade-secret protections. [Observed]
3. **Example:** Trace a specific algorithmic deployment — SSA disability determination scoring or DHS immigration risk assessment — from procurement through individual case impact, documenting the accountability gaps at each stage. [Observed]
4. **Evidence:** Present GAO findings on federal AI deployment; document the number and domains of deployed systems; show the gap between OMB/OSTP framework issuance and agency compliance. [Observed]
5. **Levers:** Evaluate algorithmic impact assessment requirements, mandatory vendor audit access clauses, APA rulemaking requirements for algorithmic systems as "final agency action," and algorithmic accountability legislation. [Hypothesis]
6. **Takeaway:** Algorithmic governance has inserted a decision-making layer into federal administration that wields regulatory power without the procedural transparency, due process, or oversight mechanisms that govern equivalent human-made decisions — a structural accountability gap that grows as deployment outpaces governance. [Inferred]
